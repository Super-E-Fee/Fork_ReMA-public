- trainer.project_name=my_study
- trainer.experiment_name=rema_replica
- trainer.nnodes=1
- trainer.n_gpus_per_node=8
- data.train_files=data/MATH/train_lv3to5_8k.parquet
- data.val_files=data/overall_math/test.parquet
- data.val_batch_size=512
- data.train_batch_size=128
- data.max_prompt_length=4096
- data.max_response_length=512
- actor_rollout_ref.model.path=/home/Documents/Fork_ReMA-public/models/Qwen2-7B-Instruct
- actor_rollout_ref.model.use_remove_padding=True
- actor_rollout_ref.actor.use_dynamic_bsz=True
- actor_rollout_ref.actor.use_kl_loss=False
- actor_rollout_ref.actor.kl_loss_coef=1e-3
- actor_rollout_ref.actor.entropy_coeff=0
- actor_rollout_ref.actor.ulysses_sequence_parallel_size=1
- actor_rollout_ref.actor.ppo_mini_batch_size=512
- actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=8
- actor_rollout_ref.actor.clip_mode=turn
- actor_rollout_ref.actor.agg_mode=trajectory
- actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=32
- actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=32
- actor_rollout_ref.rollout.tensor_model_parallel_size=1
- actor_rollout_ref.rollout.max_num_batched_tokens=8192
- actor_rollout_ref.rollout.max_num_turns=30
- actor_rollout_ref.rollout.n=16
- actor_rollout_ref.rollout.stop_when_truncated=True
- actor_rollout_ref.actor.optim.lr=1e-6
- +trainer.val_before_train=True
- +trainer.val_only=False
- +trainer.save_val_generations=True
- +trainer.save_train_generations=True
- trainer.test_freq=10
- trainer.save_freq=50
- trainer.remove_previous_ckpt_in_save=True
- trainer.total_epochs=10
- trainer.total_training_steps=500
- algorithm.adv_estimator=grpo
- reward_model.reward_manager=rema
- reward_model.mask_unfinished_reward=True
- algorithm.filter_groups.enable=False
- trainer.logger=[console,wandb]
